{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Blog authorship corpus\n",
    "https://www.kaggle.com/rtatman/blog-authorship-corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9223372036854775807"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import csv\n",
    "import word2vec\n",
    "import sys\n",
    "import gensim\n",
    "csv.field_size_limit(sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove NUL bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "800376866"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = open(\"data/blogtext.csv\", \"rb\").read()\n",
    "fo = open(\"data/blogclean.csv\", \"wb\")\n",
    "fo.write(data.replace(b\"\\x00\", b\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split up blog corpus by age group - teens (13-17), twenties (23-27), thirties (33-47)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "teenfile = open(\"data/blog10s.txt\", \"w\")\n",
    "twentyfile = open(\"data/blog20s.txt\", \"w\")\n",
    "thirtyfile = open(\"data/blog30s.txt\", \"w\")\n",
    "with open(\"data/blogclean.csv\") as blogtext:\n",
    "    reader = csv.DictReader(blogtext)\n",
    "    count = 1\n",
    "    for record in reader:\n",
    "        if int(record[\"age\"]) < 20:\n",
    "            teenfile.write(record[\"text\"]+\"\\n\")\n",
    "        elif int(record[\"age\"]) < 30:\n",
    "            twentyfile.write(record[\"text\"]+\"\\n\")\n",
    "        else:\n",
    "            thirtyfile.write(record[\"text\"]+\"\\n\")        \n",
    "teenfile.close()\n",
    "twentyfile.close()\n",
    "thirtyfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to files to phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command: word2phrase -train data/blog10s.txt -output data/blog10-phrases.txt -min-count 5 -threshold 100 -debug 2\n",
      "Starting training using file data/blog10s.txt\n",
      "Words processed: 44300K     Vocab size: 12325K  ds processed: 29500K     Vocab size: 9015K   processed: 31000K     Vocab size: 9382K  \n",
      "Vocab size (unigrams + bigrams): 6673598\n",
      "Words in train file: 44339527\n",
      "Running command: word2phrase -train data/blog20s.txt -output data/blog20-phrases.txt -min-count 5 -threshold 100 -debug 2\n",
      "Starting training using file data/blog20s.txt\n",
      "Words processed: 65600K     Vocab size: 16234K  ed: 14400K     Vocab size: 5040K  s processed: 35000K     Vocab size: 10040K  ocessed: 56000K     Vocab size: 14389K   processed: 62200K     Vocab size: 15600K  \n",
      "Vocab size (unigrams + bigrams): 8791751\n",
      "Words in train file: 65666276\n",
      "Running command: word2phrase -train data/blog30s.txt -output data/blog30-phrases.txt -min-count 5 -threshold 100 -debug 2\n",
      "Starting training using file data/blog30s.txt\n",
      "Words processed: 26700K     Vocab size: 8106K  \n",
      "Vocab size (unigrams + bigrams): 4391577\n",
      "Words in train file: 26788977\n",
      "Words written: 26700K\r"
     ]
    }
   ],
   "source": [
    "word2vec.word2phrase('data/blog10s.txt', 'data/blog10-phrases.txt', verbose=True)\n",
    "word2vec.word2phrase('data/blog20s.txt', 'data/blog20-phrases.txt', verbose=True)\n",
    "word2vec.word2phrase('data/blog30s.txt', 'data/blog30-phrases.txt', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running command: word2vec -train data/blog10-phrases.txt -output data/blog10.bin -size 100 -window 5 -sample 1e-3 -hs 0 -negative 5 -threads 12 -iter 5 -min-count 5 -alpha 0.025 -debug 2 -binary 1 -cbow 1\n",
      "Starting training using file data/blog10-phrases.txt\n",
      "Vocab size: 267751\n",
      "Words in train file: 41113901\n",
      "Alpha: 0.000002  Progress: 100.00%  Words/thread/sec: 167.20k  k  ogress: 1.89%  Words/thread/sec: 169.79k  69.81k  .024054  Progress: 3.79%  Words/thread/sec: 170.61k  read/sec: 170.75k  ec: 170.34k  Progress: 8.42%  Words/thread/sec: 170.76k  7%  Words/thread/sec: 170.54k  Progress: 13.67%  Words/thread/sec: 170.31k  ec: 170.35k  06k  70.01k  3k  ess: 23.94%  Words/thread/sec: 169.30k   Progress: 28.11%  Words/thread/sec: 168.83k  read/sec: 168.27k  .44%  Words/thread/sec: 168.35k  thread/sec: 168.35k  3k    167.87k    Progress: 38.77%  Words/thread/sec: 167.77k  : 0.015169  Progress: 39.33%  Words/thread/sec: 167.78k  ogress: 39.80%  Words/thread/sec: 167.75k  pha: 0.014722  Progress: 41.12%  Words/thread/sec: 167.63k  Progress: 41.51%  Words/thread/sec: 167.50k  4%  Words/thread/sec: 167.50k  c: 167.55k  read/sec: 167.58k  ords/thread/sec: 167.72k  12632  Progress: 49.48%  Words/thread/sec: 167.75k   167.78k  ead/sec: 167.90k  ords/thread/sec: 167.91k   0.011251  Progress: 55.00%  Words/thread/sec: 167.66k  ead/sec: 167.64k  s: 56.21%  Words/thread/sec: 167.67k  1%  Words/thread/sec: 167.40k  41k  03%  Words/thread/sec: 167.49k    Words/thread/sec: 167.46k  ess: 78.48%  Words/thread/sec: 167.38k  lpha: 0.005211  Progress: 79.16%  Words/thread/sec: 167.37k  0.005099  Progress: 79.61%  Words/thread/sec: 167.32k  ad/sec: 167.27k  26k   167.27k  ead/sec: 167.09k  Words/thread/sec: 167.07k  1%  Words/thread/sec: 166.80k  ogress: 92.21%  Words/thread/sec: 166.78k    Progress: 92.32%  Words/thread/sec: 166.78k  /thread/sec: 166.85k  c: 166.85k  ss: 96.01%  Words/thread/sec: 166.90k  Running command: word2vec -train data/blog20-phrases.txt -output data/blog20.bin -size 100 -window 5 -sample 1e-3 -hs 0 -negative 5 -threads 12 -iter 5 -min-count 5 -alpha 0.025 -debug 2 -binary 1 -cbow 1\n",
      "Starting training using file data/blog20-phrases.txt\n",
      "Vocab size: 321044\n",
      "Words in train file: 61755787\n",
      "Alpha: 0.000002  Progress: 100.00%  Words/thread/sec: 168.44k  0.024907  Progress: 0.38%  Words/thread/sec: 189.74k  s/thread/sec: 179.31k  .05%  Words/thread/sec: 173.41k  ords/thread/sec: 171.99k    Progress: 4.05%  Words/thread/sec: 172.22k  hread/sec: 170.68k  k  9.26k  lpha: 0.022073  Progress: 11.71%  Words/thread/sec: 169.06k  s: 11.85%  Words/thread/sec: 168.98k  ec: 168.89k  sec: 168.37k   0.021039  Progress: 15.85%  Words/thread/sec: 167.82k  : 0.020855  Progress: 16.58%  Words/thread/sec: 167.81k  43%  Words/thread/sec: 167.82k  lpha: 0.019582  Progress: 21.68%  Words/thread/sec: 167.88k  rds/thread/sec: 167.98k  .29%  Words/thread/sec: 167.90k  097  Progress: 23.61%  Words/thread/sec: 167.99k  85%  Words/thread/sec: 167.89k  hread/sec: 167.79k  a: 0.018205  Progress: 27.19%  Words/thread/sec: 167.84k  ss: 27.51%  Words/thread/sec: 167.88k  k  94  Progress: 30.03%  Words/thread/sec: 168.09k  s: 36.04%  Words/thread/sec: 168.62k  ead/sec: 168.73k  9.32%  Words/thread/sec: 168.81k  .66%  Words/thread/sec: 168.84k  .014761  Progress: 40.96%  Words/thread/sec: 168.92k  014654  Progress: 41.39%  Words/thread/sec: 168.95k  ords/thread/sec: 169.00k  ead/sec: 168.97k  ha: 0.013712  Progress: 45.16%  Words/thread/sec: 169.04k   Progress: 45.31%  Words/thread/sec: 169.05k  thread/sec: 169.06k  d/sec: 169.17k  ress: 51.11%  Words/thread/sec: 169.03k  s/thread/sec: 169.12k  Progress: 54.96%  Words/thread/sec: 168.96k  .95k  s: 56.05%  Words/thread/sec: 168.91k  1k  .92k  s: 56.53%  Words/thread/sec: 168.92k  a: 0.010642  Progress: 57.43%  Words/thread/sec: 168.95k   169.04k  10125  Progress: 59.50%  Words/thread/sec: 169.06k  /thread/sec: 169.09k  ss: 60.27%  Words/thread/sec: 169.10k  lpha: 0.009292  Progress: 62.84%  Words/thread/sec: 169.20k  ess: 63.65%  Words/thread/sec: 169.21k  ha: 0.008960  Progress: 64.16%  Words/thread/sec: 169.21k   Words/thread/sec: 169.36k  hread/sec: 169.37k   Words/thread/sec: 169.35k   Words/thread/sec: 169.35k  : 71.91%  Words/thread/sec: 169.28k  169.18k  lpha: 0.006452  Progress: 74.20%  Words/thread/sec: 169.14k  k  .98%  Words/thread/sec: 169.13k  s/thread/sec: 169.13k   0.005906  Progress: 76.38%  Words/thread/sec: 169.13k  005581  Progress: 77.68%  Words/thread/sec: 169.11k    Progress: 77.83%  Words/thread/sec: 169.10k  c: 169.13k  ress: 83.14%  Words/thread/sec: 169.06k  ec: 169.05k  : 83.94%  Words/thread/sec: 169.01k  4.90%  Words/thread/sec: 169.01k  ords/thread/sec: 169.02k  : 169.04k  hread/sec: 169.05k  s: 91.59%  Words/thread/sec: 168.97k    hread/sec: 168.68k  0k  rds/thread/sec: 168.57k  : 0.000471  Progress: 98.12%  Words/thread/sec: 168.58k  Running command: word2vec -train data/blog30-phrases.txt -output data/blog30.bin -size 100 -window 5 -sample 1e-3 -hs 0 -negative 5 -threads 12 -iter 5 -min-count 5 -alpha 0.025 -debug 2 -binary 1 -cbow 1\n",
      "Starting training using file data/blog30-phrases.txt\n",
      "Vocab size: 173243\n",
      "Words in train file: 25055608\n",
      "Alpha: 0.000002  Progress: 100.01%  Words/thread/sec: 169.49k  ress: 0.19%  Words/thread/sec: 146.86k  8%  Words/thread/sec: 163.20k  22%  Words/thread/sec: 161.01k  63.98k  lpha: 0.020599  Progress: 17.61%  Words/thread/sec: 164.76k  k  66.49k      Progress: 31.67%  Words/thread/sec: 167.03k  ha: 0.013707  Progress: 45.18%  Words/thread/sec: 167.96k  ogress: 48.83%  Words/thread/sec: 168.28k  thread/sec: 168.48k  s: 53.71%  Words/thread/sec: 168.51k  ress: 63.14%  Words/thread/sec: 168.70k  s/thread/sec: 168.72k  lpha: 0.008930  Progress: 64.30%  Words/thread/sec: 168.72k  Words/thread/sec: 168.79k  read/sec: 168.80k   Words/thread/sec: 168.88k  .91k  2.17%  Words/thread/sec: 168.93k  thread/sec: 168.94k  839  Progress: 88.65%  Words/thread/sec: 169.16k  lpha: 0.002530  Progress: 89.89%  Words/thread/sec: 169.18k  /thread/sec: 169.18k  "
     ]
    }
   ],
   "source": [
    "word2vec.word2vec('data/blog10-phrases.txt', 'data/blog10.bin', size=100, binary=True, verbose=True)\n",
    "word2vec.word2vec('data/blog20-phrases.txt', 'data/blog20.bin', size=100, binary=True, verbose=True)\n",
    "word2vec.word2vec('data/blog30-phrases.txt', 'data/blog30.bin', size=100, binary=True, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Word2Vec models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model10 = gensim.models.KeyedVectors.load_word2vec_format(\"data/blog10.bin\", binary=True, unicode_errors=\"ignore\")\n",
    "model20 = gensim.models.KeyedVectors.load_word2vec_format(\"data/blog20.bin\", binary=True, unicode_errors=\"ignore\")\n",
    "model30 = gensim.models.KeyedVectors.load_word2vec_format(\"data/blog30.bin\", binary=True, unicode_errors=\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
